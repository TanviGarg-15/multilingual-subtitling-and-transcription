{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffpyplayer.player import MediaPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import QDir, Qt, QUrl\n",
    "from PyQt5.QtMultimedia import QMediaContent, QMediaPlayer\n",
    "from PyQt5.QtMultimediaWidgets import QVideoWidget\n",
    "from PyQt5.QtWidgets import (QApplication, QFileDialog, QHBoxLayout, QLabel,\n",
    "        QPushButton, QSizePolicy, QSlider, QStyle, QVBoxLayout, QWidget)\n",
    "from PyQt5.QtWidgets import QMainWindow,QWidget, QPushButton, QAction\n",
    "from PyQt5.QtGui import QIcon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progress.spinner import Spinner\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.uic import loadUi\n",
    "from PyQt5.QtGui import QImage ,QPixmap ,QMovie \n",
    "from PyQt5.QtWidgets import QDialog, QApplication, QMainWindow, QMessageBox, QDialogButtonBox, QVBoxLayout, QFileDialog \n",
    "\n",
    "\n",
    "from PyQt5 import QtWidgets, QtMultimedia, uic, QtCore\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import datetime\n",
    "from googletrans import Translator\n",
    "import speech_recognition as sr\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDialog(QDialog):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomDialog, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.setWindowTitle(\"HELLO!\")\n",
    "        \n",
    "        QBtn = QDialogButtonBox.Ok | QDialogButtonBox.Cancel\n",
    "        self.flag=False\n",
    "        self.buttonBox = QDialogButtonBox(QBtn)\n",
    "        self.buttonBox.accepted.connect(self.accept)\n",
    "        self.buttonBox.rejected.connect(self.reject)\n",
    "        self.pushButton.clicked.connect(self.checkstatus) \n",
    "        self.layout = QVBoxLayout()\n",
    "        self.layout.addWidget(self.buttonBox)\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "        \n",
    "class application(QMainWindow):\n",
    "    \n",
    "    datafile=\"\"\n",
    "    translatedfile=\"\"\n",
    "    flag=0\n",
    "    datalist=[]\n",
    "    language={ 'Hindi':\"hi\",\n",
    "               'Bengali':\"bn\",\n",
    "               'Gujarati':\"gu\",\n",
    "               'Kannada':\"kn\",\n",
    "               'Marathi':\"mr\",\n",
    "               'Tamil':\"ta\",\n",
    "               'Telugu':\"te\",\n",
    "               }\n",
    "    dic={'text':'*.txt | *.docx', 'audio':'*.mp3', 'video':'*.mp4 | *.wav'}\n",
    "    font=14\n",
    "    def __init__(self):\n",
    "        super(application,self).__init__()\n",
    "        loadUi('finalapp.ui',self)\n",
    "        self.stack.setCurrentIndex(0)\n",
    "        \n",
    "        #   page1 buttons\n",
    "        self.microphone.clicked.connect(self.recordclicked)\n",
    "        self.camera.clicked.connect(lambda :self.stack.setCurrentIndex(1))\n",
    "        \n",
    "        self.p1.clicked.connect(lambda :self.stack.setCurrentIndex(0))\n",
    "        self.p2.clicked.connect(self.translateclicked)\n",
    "        self.p3.clicked.connect(self.save)\n",
    "        \n",
    "        self.text.clicked.connect(self.upload)\n",
    "        self.audio.clicked.connect(self.upload)\n",
    "        self.video.clicked.connect(self.upload)\n",
    "        \n",
    "        \n",
    "        self.pushButton.clicked.connect(self.checkstatus)\n",
    "        #   page2 buttons\n",
    "        self.record.clicked.connect(self.recordclicked)\n",
    "        \n",
    "        \n",
    "        #page4 buttons\n",
    "        self.pushButton_2.clicked.connect(self.generatesubtitles)\n",
    "        \n",
    "        # hiding elements\n",
    "        \n",
    "        \n",
    "   \n",
    "    # while using microphone for live speech recognition\n",
    "    def recordclicked(self):\n",
    "        r = sr.Recognizer()\n",
    "        m = sr.Microphone()\n",
    "        r.pause_threshold=0.3\n",
    "        r.non_speaking_duration=0.1\n",
    "        self.datalist.clear()\n",
    "        with m as source:\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "        def callback(recognizer, audio):\n",
    "                # received audio data, now we'll recognize it using Google Speech Recognition\n",
    "            try:\n",
    "                #r.pause_threshold = 1.0\n",
    "                data=r.recognize_google(audio)\n",
    "                print(data)\n",
    "                #self.datalist.append(data)\n",
    "                self.plainTextEdit_4.appendPlainText(data)\n",
    "            except sr.UnknownValueError:\n",
    "                    print(\"Google Speech Recognition could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "        \n",
    "        stop_listening=r.listen_in_background(m, callback)\n",
    "        print(\"recording started\")\n",
    "        \n",
    "        if self.microphone.isChecked()==False:\n",
    "            print(\"microphone stopping\")\n",
    "            stop_listening(wait_for_stop=False)#self.print_thread = threading.Thread(target=self.printing)\n",
    "        #self.print_thread.start()\n",
    "        #self.movie.setCacheMode(QMovie.CacheAll)\n",
    "        #self.movie1.start()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def printing(self):\n",
    "        length=0\n",
    "        while True:\n",
    "            if len(self.datalist)>length:\n",
    "                print(length,\" \",self.datalist[length])\n",
    "                self.plainTextEdit_5.appendPlainText(self.datalist[length])\n",
    "                length=length+1\n",
    "        \n",
    "       \n",
    "    \n",
    "            \n",
    "                \n",
    "    def translateclicked(self):\n",
    "        \n",
    "        if self.cbox.currentIndex()==-1:\n",
    "            msg=QMessageBox()\n",
    "            msg.setIcon(QMessageBox.Warning)\n",
    "            msg.setStandardButtons(QMessageBox.Ok | QMessageBox.Cancel)\n",
    "            msg.setText(\"Select a language First!\")\n",
    "            #msg.setInformativeText(\"This is additional information\")\n",
    "            msg.setWindowTitle(\"Warning\")\n",
    "            #msg.setDetailedText(\"The details are as follows:\")\n",
    "            msg.exec_()\n",
    "        else:\n",
    "            self.lan = str(self.cbox.currentText())\n",
    "            \n",
    "            ci= self.stack.currentIndex() \n",
    "            if ci==0:\n",
    "                translator = Translator()\n",
    "                self.datafile=self.plainTextEdit_4.toPlainText()\n",
    "                self.translatedfile=translator.translate(self.datafile, dest=self.language[self.lan]).text\n",
    "                self.plainTextEdit_3.setPlainText(self.translatedfile)\n",
    "            elif ci==3:\n",
    "                \n",
    "                translator = Translator()\n",
    "                self.datafile=self.plainTextEdit.toPlainText()\n",
    "                self.translatedfile=translator.translate(self.datafile, dest=self.language[self.lan]).text\n",
    "                self.plainTextEdit_2.setPlainText(self.translatedfile)\n",
    "            elif ci==4:\n",
    "                x=0\n",
    "                translator = Translator()\n",
    "                with open(\"subtitles.txt\", encoding='UTF-8') as f:\n",
    "                    for line in f:\n",
    "                        x=x+1\n",
    "                        if x==3:\n",
    "                            self.translatedfile=translator.translate(line, dest=self.language[self.lan]).text\n",
    "                            self.plainTextEdit_8.appendPlainText(self.translatedfile)\n",
    "                            x=-2\n",
    "                        else:\n",
    "                            self.plainTextEdit_8.appendPlainText(line)\n",
    "                f.close()\n",
    "                \n",
    "                    \n",
    "    def upload(self):\n",
    "        self.filetype=str(self.sender().objectName())\n",
    "        self.filename, _ = QFileDialog.getOpenFileName(None, caption='Select a ' + self.filetype + ' file', filter=self.dic[self.filetype])\n",
    "        if self.filetype==\"video\":\n",
    "            self.stack.setCurrentIndex(4)\n",
    "            self.videoplayer()\n",
    "            \n",
    "        else:\n",
    "            text=self.filename.split('/')[-1]\n",
    "            self.label.setText(text)\n",
    "            self.fileprint()\n",
    "        \n",
    "        \n",
    "    def videoplayer(self):\n",
    "        cap = cv2.VideoCapture(self.filename) \n",
    "        player = MediaPlayer(self.filename)\n",
    "        while(cap.isOpened()): \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            audio_frame, val = player.get_frame()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = QImage(frame, frame.shape[1], frame.shape[0], QImage.Format_RGB888)\n",
    "            pix = QPixmap.fromImage(img)\n",
    "            pix = pix.scaled(850, 650, Qt.KeepAspectRatio, Qt.SmoothTransformation)\n",
    "            self.label_12.setPixmap(pix)    \n",
    "            if val != 'eof' and audio_frame is not None:\n",
    "            #audio\n",
    "                img, t = audio_frame\n",
    "            #self.ui.frame = pix  # or img depending what `ui.frame` needs\n",
    "            if self.flag==True:\n",
    "                break\n",
    "                \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def checkstatus(self):\n",
    "        self.flag=not self.flag\n",
    "        if self.flag==False:\n",
    "            self.videoplayer()\n",
    "            self.pushButton.setIcon(QIcon(r'C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\Resources\\pause.jpg'))\n",
    "        else:\n",
    "            self.pushButton.setIcon(QIcon(r'C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\Resources\\download.jpg'))\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "        \n",
    "    def generatesubtitles(self):\n",
    "        #converting .mp4 file into .wav format\n",
    "        command1 = [\"ffmpeg\", \"-y\", \"-i\",self.filename, \"-ac\", \"1\", \"-ar\", \"16000\", r\"C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\Samplefile\\mono.wav\"]\n",
    "        subprocess.run(command1,shell=True,capture_output=True)\n",
    "\n",
    "        #getting time stamps for each spoken word of generated audio file\n",
    "        command2= r\"C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\pocketsphinx\\bin\\Release\\x64\\pocketsphinx_continuous.exe -time yes -infile C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\Samplefile\\mono.wav -hmm C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\pocketsphinx\\model\\en-us\\en-us -lm C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\pocketsphinx\\model\\en-us\\en-us.lm.bin -dict C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\pocketsphinx\\model\\en-us\\cmudict-en-us.dict > C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\textDump.txt\"\n",
    "        subprocess.run(command2,shell=True,capture_output=True)\n",
    "        \n",
    "        print('complete1')\n",
    "        #function to create subttiles\n",
    "        self.createsubtitles()\n",
    "        print('complete2')\n",
    "        \n",
    "        with open(\"subtitles.txt\", encoding='UTF-8') as f:\n",
    "                for line in f:\n",
    "                    self.plainTextEdit_7.appendPlainText(line)\n",
    "        f.close()\n",
    "        \n",
    "       \n",
    "    def createsubtitles(self):\n",
    "        f= open(\"C:/Users/GARG/Desktop/tanvi/project/majorproject/subtitles.txt\",\"w+\")\n",
    "\n",
    "        #target_date_time_ms = 2000 # or whatever\n",
    "        basetime = datetime.datetime( 1, 1, 1 )\n",
    "        #delta = datetime.timedelta( 0, 0, 0, target_date_time_ms )\n",
    "        #target_date = base_datetime + delta\n",
    "        k=1\n",
    "        file=r\"C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\textDump.txt\"\n",
    "        lookup=\"<s>\"\n",
    "        lookdown=\"</s>\"\n",
    "        prevline=\"\"\n",
    "        data=\"\"\n",
    "        tt=\"\"\n",
    "        with open(file, 'r') as myFile:\n",
    "            for num, line in enumerate(myFile, 1):\n",
    "                if lookup in line:\n",
    "                    data=prevline\n",
    "\n",
    "                    sp=line.split()\n",
    "                    start=str(basetime+datetime.timedelta( 0, 0, 0, float(sp[1])*1000))\n",
    "                    #end=str(basetime+datetime.timedelta( 0, 0, 0, float(sp[2])*1000))\n",
    "                    #print(start[0:12],end)\n",
    "                    if start[20:23]=='':\n",
    "                        sm=\"000\"\n",
    "                    else:\n",
    "                        sm=start[20:23]\n",
    "                   # if end[20:23]=='':\n",
    "                        #m=\"000\"\n",
    "                    #else:\n",
    "                        #m=end[20:23]\n",
    "                    #print(start[0][11:19])\n",
    "                    tt= start[11:19]+\",\"+sm+\" --> \"#end[11:19],\",\",em,\" \"\n",
    "\n",
    "                    #print ('found at line:', num, line,prevline, sp[1],sp[2])\n",
    "                    #=k+1\n",
    "            \n",
    "                if lookdown in line:\n",
    "                    f.write(\"%d\\n\"%k)\n",
    "                    sp=line.split()\n",
    "                    start=str(basetime+datetime.timedelta( 0, 0, 0, float(sp[1])*1000))\n",
    "                    if start[20:23]=='':\n",
    "                        sm=\"000\"\n",
    "                    else:\n",
    "                        sm=start[20:23]\n",
    "                    print(tt,start[11:19],\",\",sm,sep=\"\",file=f)#end[11:19],\",\",em,\" \"\n",
    "                    f.write(\"%s\\n\\n\"%data)\n",
    "                    tt=\"\"\n",
    "                    k=k+1\n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "                prevline=line\n",
    "        f.close()    \n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "    \n",
    "    \n",
    "    def fileprint(self):\n",
    "        if self.filetype==\"text\":\n",
    "            self.textfileprint_thread = threading.Thread(target=self.textfileprint)\n",
    "            self.textfileprint_thread.start()\n",
    "            #time.sleep(0.25)\n",
    "                    \n",
    "        if self.filetype==\"audio\":\n",
    "            msg=QMessageBox()\n",
    "            msg.setIcon(QMessageBox.Warning)\n",
    "            msg.setStandardButtons(QMessageBox.Ok)\n",
    "            msg.setText(\"Please wait your file is processing....\")\n",
    "            #msg.setInformativeText(\"This is additional information\")\n",
    "            msg.setWindowTitle(\"Warning\")\n",
    "            #msg.setDetailedText(\"The details are as follows:\")\n",
    "            msg.exec_()\n",
    "            #if self.flag==1:\n",
    "                \n",
    "            \n",
    "            \n",
    "            self.speechrecognitionprint_thread = threading.Thread(target=self.speechrecognitionprint)\n",
    "            self.speechrecognitionprint_thread.start()\n",
    "            #self.movie1=QMovie(\"resources/spinner1.gif\", QByteArray(), self)\n",
    "            #self.label_10.setMovie(self.movie1)\n",
    "            #self.movie1.start()\n",
    "            #self.label_10.show()\n",
    "            #time.sleep(0.25)\n",
    "            \n",
    "\n",
    "    \n",
    "    def save(self):\n",
    "        \n",
    "        file, _ = QFileDialog.getSaveFileName(self,\"Save File\",filter=\"*.txt\")\n",
    "        #name = QtGui.QFileDialog.getSaveFileName(self, 'Save File')\n",
    "        f = open(file,'w+',encoding='utf-8')\n",
    "        \n",
    "        f.write(self.translatedfile)\n",
    "        f.close()\n",
    "        msg=QMessageBox()\n",
    "        msg.setIcon(QMessageBox.Information)\n",
    "        msg.setStandardButtons(QMessageBox.Ok)\n",
    "        msg.setText(\"File saved successfully!\")\n",
    "        #msg.setInformativeText(\"This is additional information\")\n",
    "        msg.setWindowTitle(\"Warning\")\n",
    "            #msg.setDetailedText(\"The details are as follows:\")\n",
    "        msg.exec_()\n",
    "        \n",
    "########################################        THREADS             #######################################################\n",
    "    \n",
    "    def microphoneinput(self):\n",
    "        m = sr.Microphone()\n",
    "        r = sr.Recognizer()\n",
    "        while 1:\n",
    "            with m as source:\n",
    "                #r.adjust_for_ambient_noise(source)\n",
    "                audio = r.listen(source)\n",
    "       \n",
    "            \n",
    "            data=r.recognize_google(audio)\n",
    "        \n",
    "            self.plainTextEdit_4.setPlainText(data)\n",
    "        self.flag=1\n",
    "        self.movie.stop()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def textfileprint(self):\n",
    "        with open(self.filename, encoding='UTF-8') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        self.plainTextEdit.appendPlainText(line)\n",
    "        \n",
    "        \n",
    "    def speechrecognitionprint(self):\n",
    "        command = [\"ffmpeg\", \"-y\", \"-i\",self.filename, \"-ac\", \"1\", \"-ar\", \"16000\", r\"C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\Samplefile\\mono.wav\"]\n",
    "        subprocess.run(command,shell=True,capture_output=True)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(r\"C:\\Users\\GARG\\Desktop\\tanvi\\project\\majorproject\\Samplefile\\mono.wav\") as source:\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "            audio = r.record(source)\n",
    "            try:\n",
    "                self.datafile=r.recognize_sphinx(audio)\n",
    "                #print(type(datafile))\n",
    "                #print(\"Sphinx thinks you said \" + datafile)\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Sphinx could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Sphinx error; {0}\".format(e))\n",
    "        \n",
    "        \n",
    "        print(\"completed\")\n",
    "        self.plainTextEdit.appendPlainText(self.datafile)\n",
    "        self.stack.setCurrentIndex(3)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete1\n",
      "complete2\n",
      "complete1\n",
      "complete2\n",
      "exiting\n"
     ]
    }
   ],
   "source": [
    "app=QApplication(sys.argv)\n",
    "window=application()\n",
    "window.show()\n",
    "try:\n",
    "    sys.exit(app.exec_())\n",
    "except:\n",
    "    print('exiting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
